# -*- coding: utf-8 -*-
"""ProphetPred.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IwHaIlgM_10q7M8qPJ-XbZCFuEuwOIGb

# **CSE 6242: Data and Visual Analytics**
## *Prediction Section: Facebook Prophet*
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# Change path if needed
# %cd "drive/MyDrive/dataviz_project"

"""### Libraries import and data loading"""

import logging
import time

import pandas as pd
import numpy as np
from prophet import Prophet
import matplotlib.pyplot as plt
import plotly.graph_objects as go

from IPython.display import display
from multiprocessing import Pool, cpu_count

"""### Dataset with timeline"""

df_acc = pd.read_csv('./GA_Accidents_March23.csv', usecols = ["ID", "Start_Time"])
df_acc["Start_Time"] = pd.to_datetime(df_acc["Start_Time"], format='%Y-%m-%d %H:%M:%S', errors='coerce')

timestamp_objects = [pd.Timestamp(date_str) for date_str in df_acc["Start_Time"]]
first_date = min(timestamp_objects)
last_date = max(timestamp_objects)
print(f"First date: {first_date}")
print(f"Last date: {last_date}")

df_acc.head()

"""### Matched street accidents"""

edges = pd.read_json('./edges_matched_final.json')

"""### Original dataset"""

pre_edges = pd.read_csv('./edges.csv')

pre_edges.head()

"""# Functions definition"""

def run_prophet(df):
  '''
  Prophet model running for a given time serie in a DataFrame
  '''
  # Initialize the Prophet model
  model = Prophet(interval_width=0.8,
                  uncertainty_samples=50)
  model.fit(df)
  future = model.make_future_dataframe(periods=10, freq='M')
  forecast = model.predict(future)

  return max(forecast["trend"].iloc[-1], 0)


def process_route_group(route_group):
  '''
  Prophet running by groups for cpu boost
  '''
  return route_group.groupby('routes', group_keys=False).apply(lambda group: run_prophet(group)).to_frame(name="E_nb_acc")


def new_length(road, p):
  '''
  Safety index calculation
  '''
  return road["length"]*(1 + road["nb_acc"])**p

"""# Data preprocessing

### Select edges with accidents
"""

edges_T = edges.T
edges_T["nb_acc"] = edges_T["acc"].apply(lambda x: len(x))
edges_T = edges_T[edges_T["nb_acc"] > 0]

edges_T.head()

"""### Reverse routes and accidents"""

street_dict = edges_T["acc"].to_dict()

acc_dict = {}
for key, values in street_dict.items():
    for value in values:
        if value in acc_dict:
            acc_dict[value].append(key)
        else:
            acc_dict[value] = [key]

df_acc_route = pd.DataFrame.from_dict(acc_dict, orient='index', columns=["routes"])
df_acc_route.head()

"""### Join with accidents dataset"""

df_acc_copy = df_acc.copy()
df_acc_copy.set_index("ID", inplace=True)
df_acc_copy["Start_Time"] = pd.to_datetime(df_acc_copy["Start_Time"], format='%Y-%m-%d %H:%M:%S', errors='coerce')
df_acc_copy.head()

df_prophet = df_acc_route.merge(df_acc_copy, how="inner", left_index=True, right_index=True)
df_prophet = df_prophet.groupby(["routes", "Start_Time"]).size().reset_index(name="nb_acc")

df_prophet['year_month'] = df_prophet['Start_Time'].dt.to_period('M')
df_prophet['year_month'] = df_prophet['year_month'].dt.to_timestamp()

df_prophet = df_prophet.groupby(["routes", "year_month"])['nb_acc'].sum().reset_index()
df_prophet.head()

"""### Rename variables for Prophet"""

df_prophet.rename(columns={"year_month":"ds", "nb_acc":"y"}, inplace=True)
df_prophet.head()

"""### Filling missing dates with 0"""

unique_routes = df_prophet['routes'].unique()

date_range = pd.date_range(start='2016-06', end='2023-03', freq='MS')
date_range = pd.to_datetime(date_range, format='%Y-%m')

all_combinations = pd.DataFrame([(route, month) for route in unique_routes for month in date_range],
                                 columns=['routes', 'ds'])
all_combinations['ds'] = pd.to_datetime(all_combinations['ds'])

df_prophet = pd.merge(all_combinations, df_prophet, on=['routes', 'ds'], how='left').fillna(0)
df_prophet.head()

"""# Prophet setup and training"""

print(len(unique_routes))

"""As there are many roads with accidents, let's make a first try on a few examples."""

test_prophet = df_prophet[df_prophet["routes"].isin(unique_routes[:100])]
route_groups = [group for _, group in test_prophet.groupby('routes')]

"""### Comparison between CPU boosting and general running"""

logging.getLogger("cmdstanpy").disabled = True

start_time = time.time()
result = test_prophet.groupby('routes', group_keys=False).apply(lambda group: run_prophet(group)).to_frame(name="E_nb_acc")
print("--- %s seconds ---" % (time.time() - start_time))

logging.getLogger("cmdstanpy").disabled = False

"""Without CPU boost: 27 seconds."""

logging.getLogger("cmdstanpy").disabled = True
p = Pool(cpu_count())

start_time = time.time()
result_list = p.map(process_route_group, route_groups)
p.close()
p.join()
print("--- %s seconds ---" % (time.time() - start_time))

logging.getLogger("cmdstanpy").disabled = False

"""With CPU boost: 24 seconds.

Let's use the CPU boost for all time series.
"""

full_route_groups = [group for _, group in df_prophet.groupby('routes')]

logging.getLogger("cmdstanpy").disabled = True
p = Pool(cpu_count())

start_time = time.time()
result_list = p.map(process_route_group, full_route_groups)
p.close()
p.join()
print("--- %s seconds ---" % (time.time() - start_time))

logging.getLogger("cmdstanpy").disabled = False

acc_dict_final = dict()

for x in result_list:
  acc_dict_final[x.index[0]] = x["E_nb_acc"][0]

final_result = pd.DataFrame.from_dict(acc_dict_final, orient='index', columns=["nb acc"])

final_result.head()

"""Let's now save the dataset to not have to run the accident estimation again."""

final_result.to_csv("estimated_nb_acc.csv")

"""# Final lengths calculation based on the safety index

### Data loading
"""

final_result = pd.read_csv("./estimated_nb_acc.csv", names=["id", "nb_acc"], header=None, skiprows=1)

new_edges = final_result.merge(pre_edges.set_index("id"), how="outer", on="id")
new_edges.fillna(0, inplace=True)
new_edges.head()

"""### Choice of p-value"""

p_values = [1.25, 1.5, 1.75, 2, 2.5]

for p in p_values:
    column_name = f"length_gabriel_{p}"
    new_edges[column_name] = new_edges.apply(lambda x: new_length(x, p=p), axis=1)

new_edges[new_edges["nb_acc"] > 0][["length", "nb_acc", "length_gabriel_1.25", "length_gabriel_1.5", "length_gabriel_1.75", "length_gabriel_2", "length_gabriel_2.5" ]]

w_acc_curr = 100
p_values = [1.25, 1.5, 1.75, 2, 2.5]
nb_acc_pred = np.linspace(0, 10, 100)

fig = go.Figure()
fig.update_layout(title='Single Plot for Different Values of p')

for p in p_values:
    nb_acc_new = w_acc_curr*((1 + nb_acc_pred)**p)
    fig.add_trace(go.Scatter(x=nb_acc_pred, y=nb_acc_new, mode='lines', name=f'p = {p}'))

fig.update_layout(xaxis_title='nb_acc_pred', yaxis_title='nb_acc_new', showlegend=True, autosize=False,
    width=1000,
    height=700)

fig.show()

"""Let's take $p=2$, which seems to penalize roads with a high number of estimated accidents without giving inconsistent values like for $p=2.5$"""

new_edges.drop(columns=["length_gabriel_1.25", "length_gabriel_1.5", "length_gabriel_1.75", "length_gabriel_2.5"], inplace=True)
new_edges.rename({"length_gabriel_2": "length_gabriel"}, inplace=True)

new_edges.to_csv("new_edges_dataset.csv")

"""# A Prophet plot"""

# Road id
road_id = "1001112568-0"

# Initialize the Prophet model
logging.getLogger("cmdstanpy").disabled = True
model = Prophet(interval_width=0.8,
                uncertainty_samples=50)

# Fit the model
model.fit(df_prophet[df_prophet["routes"]==road_id])

# Create a dataframe with dates for the next month
future = model.make_future_dataframe(periods=10, freq='M')

# Make predictions
forecast = model.predict(future)
logging.getLogger("cmdstanpy").disabled = False

plt.figure(dpi=300)
# Plot the forecast
fig = model.plot(forecast)
plt.title(f'Accident Prediction for Next Month on road {road_id}')
plt.xlabel('Date')
plt.ylim(-2, 4.1)
plt.ylabel('Number of Accidents')
plt.show()